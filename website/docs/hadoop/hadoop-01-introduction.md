---
layout: post
title: 读书笔记：1-初识 Hadoop
date: 2021-01-19 09:09:54
tags:
- Start with Me
- Book
categories:
- Reading
---

《Hadoop 权威指南》读书笔记第一篇带你初步了解一下 Hadoop

<!-- more -->

# 1 初识Hadoop

Hadoop 是一个数据存储和分析的分布式系统

## 1.1 数据

### 大量数据

不仅仅是公司才面对着大量数据，对于个人来说，也是如此。最近心血来潮开始拍视频，然后 50G 存储空间都不够用了，换了 200G 的方案，希望可以永久一点，或者是，少产生点数据。

### 大量数据的好处

大数据的意义 > 好算法，大概就是全样本的优势了叭

## 1.2 数据的存储与分析

数据传输速度没有与时俱进，大容量的硬盘传输时间久

采用并行传输的思想，通过硬盘共享可以解决，有一定的可行性

多个硬盘并行进度读/写数据的问题

### 并行读写的问题

- 硬件故障
    - 避免数据丢失 —— 复制 replication
    - 解决方法：**HDFS** Hadoop Distributed FileSystem
- 数据分析需要结合多个硬盘的数据
    - 解决方法：**MapReduce**

### Hadoop 提供了可靠可扩展的存储和分析平台

## 1.3 查询所有数据

**MapReduce**

- 每个查询需要处理整个数据集或至少一个数据集的绝大部分
- 可以在合理的时间范围内处理针对整个数据集的动态查询

## 1.4 不仅仅是批处理

MapReduce 是批处理系统，但是更适合那种没有用户在现场等待查询结果的离线场景，需要一定的等待时间，**不适合交互式分析**

Hadoop

- 随着发展，超越了批处理本身
- 指代一个更大的、多个项目（分布式计算、大规模数据处理）组成的生态系统
- not only HDFS and MapReduce

### Hadoop 的其他处理框架

- 迭代处理
    - Spark
    - 因为很多机器学习都是迭代，内存中保存每次**中间结果集**，而不是每次迭代都从硬盘中加载
- 流处理
    - Storm 、Spark Streaming 、 Samza
    - 数据流上运行**实时、分布式**的计算
- 搜索
    - Solr
    - 搜索查询

### MapReduce 的概念更具有通用性

- 输入格式
- 数据集分片

## 1.5 相较于其他系统的优势

### 关系型数据库管理系统

- 硬盘寻址时间的提升远远不敌于传输速率的提升
- 寻址：磁头移动到特定硬盘位置进行读/写的过程

    ---

    *现在几乎没有机械硬盘来做数据库存储了，都是固态硬盘；固态硬盘不存在寻址的问题，而且速度非常快。*

    ---

- 如果更新一小部分记录，关系数据库的 **B树** 结构更有优势
- 如果有大量数据需要更新，B树 的效率落后于MapReduce，因为需要 排序/合并 来重建数据库
- Hadoop 和 关系型数据库的区别
    - 区别开始模糊
        - **Hive** 这样的 Hadoop 系统变得具有交互性（从MapReduce中脱离出来），而且增加了索引、事务，看起来更像传统的关系型数据库
    - 不同类型的数据处理
        - Hadoop 对于**非结构化数据或半结构化数据**非常有效（如：电子表格、纯文本、图像）
            - 结构化、半结构化、非结构化数据
                - 结构化数据
                    - XML
                - 半结构化数据
                    - 电子表格
                    - 每个单元格的数据类型是不固定的
                - 非结构化数据
                    - 纯文本、图像
    - 规范化
        - 关系型数据库是规范的 normalized，保证数据的完整性、不含冗余，满足 3NF/BCNF
        - 但是规范会给 Hadoop 处理带来问题，因为使得记录读取成为非本地操作

### 网格计算

- 大规模数据处理
    - 主要采用类似于[消息传递接口](https://mpitutorial.com/tutorials/)(*Message Passing Interface*)的 API
    - HPC 高性能计算 *High Performance Computing*
        - 将作业分散到集群的各台机器上，这些机器访问存储区域网络 SAN 所组成的共享文件系统
        - 适合计算密集型的作业
    - 网格计算 *Grid Computing*
    - Hadoop
        - 如果节点需要访问的数据量更庞大，很多计算节点就会因为网络带宽的瓶颈问题而不得不闲下来等数据  —>  Hadoop

        ---

        网络带宽是什么？
        - 网络带宽是**数据通道的最大承载量**，例如 4G 最大速度是多少多少 Mbps，代表 1 秒内最多能传输这么多的数据，再多就堵车了
        - 运行效率的两大瓶颈，算力和带宽，大概可以用高速公路收费站来理解一下
        - 路相对带宽，收费站相对算力
        - 路太宽收费站不够就会堵车（带宽不足），收费站太多就会产生浪费（算力不足）

        ---

        - 尽量在计算节点上存数据，以实现数据的**本地快速访问**
        - 数据处理的核心 **数据本地化**
        - 通过**显式网络拓扑结构**来保留网络带宽，并没有降低对计算密集型数据进行分析的能力
            - 因为网络带宽是数据中心环境最珍贵的资源，到处复制数据很容易耗尽网络带宽

            ---

            **显式网络拓扑结构是什么？**
            猜测这里的意思是，配置 Hadoop 集群的时候，会把不同的节点之间的连接显式 (*Explicit*) 地定义好，有了一张图之后，Hadoop 就可以知道如果要把数据从机器 A 传输到机器 B，最短路径（消耗带宽最少的路径）是什么，以此来节省网络带宽
            **为什么网络带宽最珍贵？**
            算力可以堆，存储可以堆，但是这代表网络复杂性会增加，那么数据传输的成本就会增加，所以带宽会非常珍贵

            ---

        - MapReduce
            - 分布式处理框架
            - 不用担心操作系统失效问题（不知道一个远程进程是否挂了）
            - 框架可以检测到失败的任务并重新在正常的机器上执行
            - 采用无共享框架
            - 各个任务之间是彼此独立的，任务的执行顺序无关紧要

### 志愿计算

> 为科学而计算

点击[这里](https://boinc.berkeley.edu/)，了解 BOINC

- 搜索最大素数 项目
    - *Great Internet Mersenne Prime Search*
    - 点击[这里](https://www.mersenne.org/)搜寻最大素数
- `Folding@home` 项目
    - 了解蛋白质构成及其与疾病之间的关系
    - 点击[这里](https://foldingathome.org/)了解详情
- `SETI@home` 项目
    - 志愿者将计算机CPU空闲时间贡献出来分析无线天文望远镜的数据
    - 点击[这里](https://setiathome.berkeley.edu/)搜寻外星智慧叭
- MapReduce vs `SETI@home`
    - 两者看起来类似，都是将问题分为独立的小块，然后并行计算
    - `SETI@home`  是 CPU 密集型的，适合在全球成千上万台计算机上运行，因为计算所花的时间远超过工作单元数据的传输时间
    - 志愿者贡献的是 CPU 周期，而不是 **网络带宽**

    ---

    - CPU 周期可以理解成算力，周期是 CPU 执行指令的最小单位
    - 因为他们是把原始数据拖到自己电脑上计算，把计算后的结果上传，经过计算信息密度会更高，所以贡献的并不是网络带宽

    ---

    - `SETI@home` 使用的是不可信的计算机
    - MapReduce ——  数据本地化

## Summary

Hadoop 出现的意义 —— 大数据、

Hadoop 区别其他系统的优势
